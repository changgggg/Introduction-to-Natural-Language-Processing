{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a2bfAz-dk48L"
      },
      "outputs": [],
      "source": [
        "pip install underthesea"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "import string\n",
        "import unicodedata\n",
        "import re\n",
        "import underthesea\n",
        "from collections import Counter"
      ],
      "metadata": {
        "id": "A4ZvmUqUMpyH"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Đọc dữ liệu từ file CSV\n",
        "data = pd.read_csv(\"facebook_comment_2k7.csv\")\n",
        "\n",
        "# Tiền xử lý dữ liệu văn bản tiếng Việt\n",
        "def preprocess_text_vietnamese(text):\n",
        "    # Chuyển văn bản về chữ thường\n",
        "    text = text.lower()\n",
        "    # Loại bỏ dấu câu\n",
        "    text = text.translate(str.maketrans(\"\", \"\", string.punctuation))\n",
        "    # Loại bỏ dấu ký tự đặc biệt\n",
        "    text = re.sub(r'[^\\w\\s]', '', text)\n",
        "    # Tách từ tiếng Việt\n",
        "    words = underthesea.word_tokenize(text)\n",
        "    # Ghép từ lại thành câu\n",
        "    text = ' '.join(words)\n",
        "    return text"
      ],
      "metadata": {
        "id": "JOLgcCmyMrjq"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define models\n",
        "models = {\n",
        "    \"Logistic Regression\": make_pipeline(TfidfVectorizer(preprocessor=preprocess_text_vietnamese, max_features=10000), LogisticRegression()),\n",
        "    \"Naive Bayes\": make_pipeline(TfidfVectorizer(preprocessor=preprocess_text_vietnamese, max_features=10000), MultinomialNB()),\n",
        "    \"Random Forest\": make_pipeline(TfidfVectorizer(preprocessor=preprocess_text_vietnamese, max_features=10000), RandomForestClassifier()),\n",
        "    \"SVM\": make_pipeline(TfidfVectorizer(preprocessor=preprocess_text_vietnamese, max_features=10000), SVC(kernel='linear')),\n",
        "    \"KNeighbors\": make_pipeline(TfidfVectorizer(preprocessor=preprocess_text_vietnamese, max_features=10000), KNeighborsClassifier(n_neighbors=5)),\n",
        "    \"MLP\": make_pipeline(TfidfVectorizer(preprocessor=preprocess_text_vietnamese, max_features=10000), MLPClassifier()),\n",
        "    \"Gradient Boosting\": make_pipeline(TfidfVectorizer(preprocessor=preprocess_text_vietnamese, max_features=10000), GradientBoostingClassifier())\n",
        "}"
      ],
      "metadata": {
        "id": "6HizPPsgMsQ_"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train models\n",
        "for name, model in models.items():\n",
        "    model.fit(data['text'], data['label'])"
      ],
      "metadata": {
        "id": "UPDHMASUMws6"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define predict_labels function\n",
        "def predict_labels(input_sentence):\n",
        "    # Predict labels using all models\n",
        "    predictions = {name: model.predict([input_sentence])[0] for name, model in models.items()}\n",
        "\n",
        "    # Count label occurrences\n",
        "    label_counter = Counter(predictions.values())\n",
        "\n",
        "    # Get most common labels\n",
        "    most_common_labels = [label for label, count in label_counter.items() if count >= 4]\n",
        "\n",
        "    # Return \"Uncertain\" if no label is predicted more than 4 times\n",
        "    if not most_common_labels:\n",
        "        return [\"Uncertain\"]\n",
        "\n",
        "    return most_common_labels"
      ],
      "metadata": {
        "id": "bpUuiK1yMwvs"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get user input\n",
        "input_sentence = input(\"Nhập câu: \")\n",
        "\n",
        "# Predict labels for the input sentence\n",
        "predicted_labels = predict_labels(preprocess_text_vietnamese(input_sentence))\n",
        "print(\"Dự đoán nhãn:\", predicted_labels)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LZNftW8qL7WW",
        "outputId": "d9349b43-9900-402c-826b-7bc97d2f69f3"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Nhập câu: hi em\n",
            "Dự đoán nhãn: [\"['normal']\"]\n"
          ]
        }
      ]
    }
  ]
}