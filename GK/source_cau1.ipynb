{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3fbb1ef1-a2c1-44a6-9cd9-25377dc1d11b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/longnguyen/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from gensim.models import Word2Vec\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np\n",
    "from nltk.corpus import stopwords\n",
    "import nltk\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "998fe1ce-8892-409b-8328-99f9667af694",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example sentences for training\n",
    "S = [\n",
    "    \"The quick brown fox jumps over the lazy dog.\",\n",
    "    \"She sells seashells by the seashore.\", \n",
    "    \"The cat sat on the mat.\",\n",
    "    \"A stitch in time saves nine.\",\n",
    "    \"Rome wasn't built in a day.\",\n",
    "    \"Where there's a will, there's a way.\",\n",
    "    \"Actions speak louder than words.\",\n",
    "    \"All's well that ends well.\",\n",
    "    \"Beauty is in the eye of the beholder.\",\n",
    "    \"Time flies when you're having fun.\",\n",
    "    \"The early bird catches the worm.\",\n",
    "    \"Don't count your chickens before they hatch.\",\n",
    "    \"A penny saved is a penny earned.\",\n",
    "    \"Every cloud has a silver lining.\",\n",
    "    \"Haste makes waste.\",\n",
    "    \"The sun rises in the east and sets in the west.\",\n",
    "    \"Life is like a box of chocolates, you never know what you're gonna get.\",\n",
    "    \"Two wrongs don't make a right, but three lefts do.\",\n",
    "    \"Laughter is timeless, imagination has no age, and dreams are forever.\",\n",
    "    \"The only way to do great work is to love what you do.\",\n",
    "    \"The journey of a thousand miles begins with a single step.\",\n",
    "    \"Success is not final, failure is not fatal: It is the courage to continue that counts.\",\n",
    "    \"Education is the most powerful weapon which you can use to change the world.\",\n",
    "    \"In the middle of difficulty lies opportunity.\",\n",
    "    \"The best way to predict the future is to create it.\",\n",
    "    \"Life is what happens when you're busy making other plans.\",\n",
    "    \"Believe you can and you're halfway there.\",\n",
    "    \"The future belongs to those who believe in the beauty of their dreams.\", \n",
    "    \"Be yourself; everyone else is already taken.\",\n",
    "    \"It does not matter how slowly you go as long as you do not stop.\",\n",
    "    \"Embrace your uniqueness; there's no one else quite like you.\",\n",
    "    \"Stay true to who you are; there's nobody else quite like you.\"\n",
    "    \"The bank by the river has a beautiful view.\",\n",
    "    \"She used a sharp knife to cut the cake.\",\n",
    "    \"The crane lifted heavy loads at the construction site.\",\n",
    "    \"The crane watched the flock of birds flying overhead.\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "13dc5275-43cc-4576-9c97-136a3bee2a86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most similar sentence with CBOW: The crane watched the flock of birds flying overhead.\n",
      "Similarity score with CBOW: 0.45683396\n",
      "\n",
      "Most similar sentence with Skip-gram: The crane watched the flock of birds flying overhead.\n",
      "Similarity score with Skip-gram: 0.45727187\n"
     ]
    }
   ],
   "source": [
    "# Preprocess a sentence\n",
    "def preprocess_sentence(sentence):\n",
    "    tokens = word_tokenize(sentence.lower())  # Tokenize and lowercase\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    tokens = [word for word in tokens if word.isalpha() and word not in stop_words]  # Remove stopwords and punctuation\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    tokens = [lemmatizer.lemmatize(word) for word in tokens]  # Lemmatize\n",
    "    return tokens\n",
    "\n",
    "# Preprocess all sentences in S\n",
    "preprocessed_S = [preprocess_sentence(sentence) for sentence in S]\n",
    "\n",
    "# Train Word2Vec model with CBOW\n",
    "model_cbow = Word2Vec(preprocessed_S, vector_size=100, window=5, min_count=1, workers=4, sg=0)\n",
    "\n",
    "# Train Word2Vec model with Skip-gram\n",
    "model_skipgram = Word2Vec(preprocessed_S, vector_size=100, window=5, min_count=1, workers=4, sg=1)\n",
    "\n",
    "# Function to compute average word embedding of a sentence\n",
    "def average_word_embedding(sentence_tokens, model):\n",
    "    embeddings = []\n",
    "    for token in sentence_tokens:\n",
    "        if token in model.wv:\n",
    "            embeddings.append(model.wv[token])\n",
    "    if embeddings:\n",
    "        return np.mean(embeddings, axis=0)\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "# Function to find most similar sentence using a given model\n",
    "def most_similar_sentence_with_model(X, S, model):\n",
    "    X_tokens = preprocess_sentence(X)\n",
    "    X_embedding = average_word_embedding(X_tokens, model)\n",
    "    if X_embedding is None:\n",
    "        return None\n",
    "    max_similarity = -1\n",
    "    most_similar_sentence = None\n",
    "    for sentence in S:\n",
    "        sentence_tokens = preprocess_sentence(sentence)\n",
    "        sentence_embedding = average_word_embedding(sentence_tokens, model)\n",
    "        if sentence_embedding is not None:\n",
    "            similarity = cosine_similarity([X_embedding], [sentence_embedding])[0][0]\n",
    "            if similarity > max_similarity:\n",
    "                max_similarity = similarity\n",
    "                most_similar_sentence = sentence\n",
    "    return most_similar_sentence, max_similarity\n",
    "\n",
    "# Given sentence X\n",
    "X = \"The crane\"\n",
    "\n",
    "# Find most similar sentence using CBOW model\n",
    "most_similar_cbow, similarity_score_cbow = most_similar_sentence_with_model(X, S, model_cbow)\n",
    "\n",
    "# Find most similar sentence using Skip-gram model\n",
    "most_similar_skipgram, similarity_score_skipgram = most_similar_sentence_with_model(X, S, model_skipgram)\n",
    "\n",
    "print(\"Most similar sentence with CBOW:\", most_similar_cbow)\n",
    "print(\"Similarity score with CBOW:\", similarity_score_cbow)\n",
    "\n",
    "print(\"\\nMost similar sentence with Skip-gram:\", most_similar_skipgram)\n",
    "print(\"Similarity score with Skip-gram:\", similarity_score_skipgram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b2d4b25f-75cd-4fa0-b795-49e402edcef2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pre-trained GloVe word embeddings manually\n",
    "def load_glove_embeddings(file_path):\n",
    "    word_vectors = {}\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            values = line.split()\n",
    "            word = values[0]\n",
    "            vector = np.asarray(values[1:], dtype='float32')\n",
    "            word_vectors[word] = vector\n",
    "    return word_vectors\n",
    "\n",
    "# Load pre-trained GloVe word embeddings\n",
    "glove_file = './glove.6B.50d.txt'  # Change path to the location of your GloVe file\n",
    "word_vectors = load_glove_embeddings(glove_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "02426017-f8f4-48d4-bc18-69330a31a9ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most similar sentence: The crane lifted heavy loads at the construction site.\n",
      "Similarity score: 0.7860202\n"
     ]
    }
   ],
   "source": [
    "# Function to compute average word embedding of a sentence using GloVe embeddings\n",
    "def average_word_embedding(sentence_tokens):\n",
    "    embeddings = []\n",
    "    for token in sentence_tokens:\n",
    "        if token in word_vectors:\n",
    "            embeddings.append(word_vectors[token])\n",
    "    if embeddings:\n",
    "        return np.mean(embeddings, axis=0)\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "# Function to find most similar sentence using GloVe embeddings\n",
    "def most_similar_sentence(X, S):\n",
    "    X_tokens = preprocess_sentence(X)\n",
    "    X_embedding = average_word_embedding(X_tokens)\n",
    "    if X_embedding is None:\n",
    "        return None\n",
    "    max_similarity = -1\n",
    "    most_similar_sentence = None\n",
    "    for i, sentence in enumerate(S):\n",
    "        sentence_tokens = preprocess_sentence(sentence)\n",
    "        sentence_embedding = average_word_embedding(sentence_tokens)\n",
    "        if sentence_embedding is not None:\n",
    "            similarity = cosine_similarity([X_embedding], [sentence_embedding])[0][0]\n",
    "            if similarity > max_similarity:\n",
    "                max_similarity = similarity\n",
    "                most_similar_sentence = sentence\n",
    "    return most_similar_sentence, max_similarity\n",
    "\n",
    "# Given sentence X\n",
    "X = \"The crane lifted\"\n",
    "\n",
    "# Find most similar sentence using GloVe embeddings\n",
    "most_similar, similarity_score = most_similar_sentence(X, S)\n",
    "print(\"Most similar sentence:\", most_similar)\n",
    "print(\"Similarity score:\", similarity_score)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
